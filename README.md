# ğŸš€ CLIP-based Image Clustering and Remove Similar Images

<img src="assets/figure_0.png" width="800" alt="Overall Workflow">

A tool for finding and managing similar images using CLIP (Contrastive Language-Image Pre-Training) vision encoder. This tool helps you identify and organize similar images, and can be used to remove similar images based on a configurable similarity threshold.

## Key Features

- Generate image embeddings using CLIP vision encoder
- Cluster similar images based on cosine similarity
- Visualize image clusters for easy analysis
- Remove similar images based on configurable threshold
- Configurable similarity threshold

## Example Results
Here are some example clusters from the visualization step.

<img src="results/visualization/cluster_002.jpg" width="600" alt="Cluster Example 1">

<img src="results/visualization/cluster_004.jpg" width="600" alt="Cluster Example 2">

<img src="results/visualization/cluster_006.jpg" width="600" alt="Cluster Example 3">

## Installation

```bash
git clone https://github.com/ldj7672/Similar-Image-Finder.git
cd Similar-Image-Finder
pip install -r requirements.txt
```

### CLIP Model Setup

The tool uses the CLIP model from Hugging Face. There are two ways to set up the model.

1. **Automatic Download (Default)**
   - The model will be automatically downloaded from Hugging Face on first run
   - Default model: `openai/clip-vit-base-patch32`
   - The model will be cached in your local Hugging Face cache directory

2. **Using Local Model**
   - If you already have the CLIP model downloaded, you can specify its path in the config file:
   ```yaml
   model:
     name: "path/to/your/local/clip/model"
   ```

## Quick Start

**1. Generate image embeddings**
```bash
python src/generate_embeddings.py --image_dir path/to/images --output_dir path/to/embeddings
```

**2. Cluster similar images**
```bash
python src/cluster_images.py --embedding_dir path/to/embeddings --threshold 0.95
```

The clustering results are saved in the following JSON format.
```json
{
  "metadata": {
    "threshold": 0.94,
    "total_images": 22,
    "total_clusters": 7,
    "timestamp": "20250515_151708"
  },
  "clusters": [
    ["0", "1"],
    ["10", "9"],
    ["11", "12"],
    ["15", "16", "17"],
    ["18", "19"],
    ["20", "21"],
    ["4", "5"]
  ]
}
```

**3. Visualize results**
```bash
python src/visualize_clusters.py --result_file path/to/clustering_result.json --image_dir path/to/images
```

**4. Remove similar images**
```bash
python src/remove_similar_images.py \
    --result_file path/to/clustering_result.json \
    --image_dir path/to/images \
    --keep_first
```

This will:
- Keep one representative image from each cluster (first image by default)
- Delete other similar images based on the threshold
- Log the number of deleted images

## Configuration Options

- `--threshold`: Similarity threshold (default: 0.95)
  - For removing very similar images: 0.94-0.96 recommended
  - For finding related images: 0.85-0.93 recommended
- `--batch_size`: Batch processing size (default: 1000)
- `--device`: Device to use (cuda/cpu/mps)

## Project Structure

```
similar-image-finder/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ clip_encoder.py      # CLIP model for image encoding
â”‚   â”œâ”€â”€ image_clusterer.py   # Image clustering logic
â”‚   â”œâ”€â”€ visualizer.py        # Result visualization
â”‚   â”œâ”€â”€ remove_duplicates.py # Remove similar images
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default_config.yaml  # Configuration settings
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## í•œê¸€ ê°€ì´ë“œ

### ê°„ë‹¨ ì†Œê°œ
ì´ ë ˆí¬ëŠ” CLIP Vision Encoderë¥¼ í™œìš©í•˜ì—¬ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ê³  ê´€ë¦¬í•˜ëŠ” ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ê·¸ë£¹í™”í•˜ì—¬ ë¶„ì„
- ì„ê³„ê°’ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì œê±°
- ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ì •ë¦¬

### Quick Start

**1. ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±í•˜ê¸°**
```bash
python src/generate_embeddings.py --image_dir path/to/images --output_dir path/to/embeddings
```

**2. ìœ ì‚¬í•œ ì´ë¯¸ì§€ í´ëŸ¬ìŠ¤í„°ë§**
```bash
python src/cluster_images.py --embedding_dir path/to/embeddings --threshold 0.95
```

í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì€ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.
```json
{
  "metadata": {
    "threshold": 0.94,
    "total_images": 22,
    "total_clusters": 7,
    "timestamp": "20250515_151708"
  },
  "clusters": [
    ["0", "1"],
    ["10", "9"],
    ["11", "12"],
    ["15", "16", "17"],
    ["18", "19"],
    ["20", "21"],
    ["4", "5"]
  ]
}
```

**3. ê²°ê³¼ ì‹œê°í™”**
```bash
python src/visualize_clusters.py --result_file path/to/clustering_result.json --image_dir path/to/images
```

**4. ìœ ì‚¬ ì´ë¯¸ì§€ ì œê±°**
```bash
python src/remove_similar_images.py \
    --result_file path/to/clustering_result.json \
    --image_dir path/to/images \
    --keep_first
```

ì´ ëª…ë ¹ì–´ëŠ” ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ì‚­ì œí•©ë‹ˆë‹¤. `--keep_first` ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ í´ëŸ¬ìŠ¤í„°ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ìœ ì§€í•˜ê³ , ì´ ì˜µì…˜ì„ ì œê±°í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

### Threshold ì„¤ì • ê°€ì´ë“œ
ì´ë¯¸ì§€ ìœ ì‚¬ë„ ì„ê³„ê°’ì€ ìš©ë„ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ìœ ì‚¬ ì´ë¯¸ì§€ ì œê±°ìš© (0.94 ~ 0.96)
   - ë§¤ìš° ìœ ì‚¬í•œ ì´ë¯¸ì§€ë§Œ ì œê±°í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
   - 0.94: ì•½ê°„ ë” ê´€ëŒ€í•œ ê¸°ì¤€
   - 0.96: ë§¤ìš° ì—„ê²©í•œ ê¸°ì¤€

2. ê´€ë ¨ ì´ë¯¸ì§€ ê·¸ë£¹í™”ìš© (0.85 ~ 0.93)
   - ë¹„ìŠ·í•œ ì£¼ì œë‚˜ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©
   - 0.85: ë„“ì€ ë²”ìœ„ì˜ ê´€ë ¨ ì´ë¯¸ì§€ í¬í•¨
   - 0.93: ë” ì¢ì€ ë²”ìœ„ì˜ ìœ ì‚¬ ì´ë¯¸ì§€ í¬í•¨
